{"cells":[{"cell_type":"code","execution_count":7,"id":"45956141","metadata":{"execution":{"iopub.execute_input":"2025-08-09T20:31:23.564352Z","iopub.status.busy":"2025-08-09T20:31:23.563989Z","iopub.status.idle":"2025-08-09T20:31:27.120983Z","shell.execute_reply":"2025-08-09T20:31:27.120106Z","shell.execute_reply.started":"2025-08-09T20:31:23.564320Z"},"trusted":true},"outputs":[],"source":["import os\n","os.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n","# Uncomment if chromadb is not installed\n","!pip install --quiet chromadb transformers torch"]},{"cell_type":"code","execution_count":8,"id":"ce2d7dc9","metadata":{"execution":{"iopub.execute_input":"2025-08-09T20:31:27.122708Z","iopub.status.busy":"2025-08-09T20:31:27.122444Z","iopub.status.idle":"2025-08-09T20:31:27.127848Z","shell.execute_reply":"2025-08-09T20:31:27.127129Z","shell.execute_reply.started":"2025-08-09T20:31:27.122684Z"},"trusted":true},"outputs":[],"source":["\n","import os\n","import json\n","import numpy as np\n","import torch\n","from transformers import AutoTokenizer, AutoModel\n","import chromadb\n","\n","# Config\n","MODEL_NAME = 'intfloat/e5-base-v2'\n","CHROMA_PATH = 'hajj_e5_chroma'\n","COLLECTION_NAME = 'hajj_e5'\n","\n","# Prefixes\n","PASSAGE_PREFIX = 'passage: '\n","QUERY_PREFIX = 'query: '\n","\n","# Paths to load data\n","JSON_PATH = '/kaggle/input/rijvxetjkr3wkr/hajj_chunks_e5.json'\n","NPY_PATH = '/kaggle/input/rijvxetjkr3wkr/hajj_embeddings_e5.npy'\n"]},{"cell_type":"code","execution_count":9,"id":"4b148223","metadata":{"execution":{"iopub.execute_input":"2025-08-09T20:31:27.129127Z","iopub.status.busy":"2025-08-09T20:31:27.128855Z","iopub.status.idle":"2025-08-09T20:31:27.859949Z","shell.execute_reply":"2025-08-09T20:31:27.859146Z","shell.execute_reply.started":"2025-08-09T20:31:27.129104Z"},"trusted":true},"outputs":[],"source":["\n","# Load model and tokenizer for query encoding\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","model = AutoModel.from_pretrained(MODEL_NAME)\n","model.to(device)\n","model.eval()\n","\n","# Helper to encode and normalise text\n","def embed_query(text: str):\n","    input_text = QUERY_PREFIX + text\n","    encoded = tokenizer(input_text, return_tensors='pt', truncation=True, max_length=512)\n","    encoded = {k: v.to(device) for k, v in encoded.items()}\n","    with torch.no_grad():\n","        out = model(**encoded)\n","        token_embeds = out.last_hidden_state\n","        mask = encoded['attention_mask'].unsqueeze(-1)\n","        sum_embeds = (token_embeds * mask).sum(dim=1)\n","        sum_mask = mask.sum(dim=1)\n","        embed = (sum_embeds / sum_mask).squeeze(0).cpu().numpy()\n","    # Normalise\n","    norm = np.linalg.norm(embed)\n","    if norm > 0:\n","        embed = embed / norm\n","    return embed\n"]},{"cell_type":"code","execution_count":10,"id":"d1452e03","metadata":{"execution":{"iopub.execute_input":"2025-08-09T20:31:27.861791Z","iopub.status.busy":"2025-08-09T20:31:27.861558Z","iopub.status.idle":"2025-08-09T20:31:28.781406Z","shell.execute_reply":"2025-08-09T20:31:28.780864Z","shell.execute_reply.started":"2025-08-09T20:31:27.861774Z"},"trusted":true},"outputs":[],"source":["# Load cross-encoder for re-ranking\n","try:\n","    from transformers import AutoTokenizer as CETokenizer, AutoModelForSequenceClassification\n","    ce_model_name = 'cross-encoder/ms-marco-MiniLM-L-6-v2'\n","    ce_tokenizer = CETokenizer.from_pretrained(ce_model_name)\n","    ce_model = AutoModelForSequenceClassification.from_pretrained(ce_model_name)\n","    ce_model.to(device)\n","    ce_model.eval()\n","    USE_CROSS_ENCODER = True\n","except Exception as e:\n","    print(f\"Failed to load cross-encoder model: {e}\")\n","    USE_CROSS_ENCODER = False\n","\n","# Define re-ranking function using cross-encoder\n","def rerank_cross_encoder(query_str, candidates):\n","    \"\"\"\n","    Re-rank candidate documents using a cross-encoder.\n","    Args:\n","        query_str (str): The user query.\n","        candidates (list[dict]): List of candidate hits returned by vector search.\n","    Returns:\n","        list[dict]: Candidates sorted by cross-encoder score.\n","    \"\"\"\n","    if not USE_CROSS_ENCODER or len(candidates) == 0:\n","        return candidates\n","    # Prepare text pairs\n","    queries = [query_str] * len(candidates)\n","    docs = [c['text'] for c in candidates]\n","    enc = ce_tokenizer(queries, docs, padding=True, truncation=True, return_tensors='pt').to(device)\n","    with torch.no_grad():\n","        logits = ce_model(**enc).logits.squeeze()\n","    # Ensure logits is 1D\n","    scores = logits.cpu().numpy().flatten().tolist()\n","    for cand, s in zip(candidates, scores):\n","        cand['cross_score'] = float(s)\n","    # Sort by cross-encoder score (higher is better)\n","    candidates.sort(key=lambda x: x.get('cross_score', 0), reverse=True)\n","    return candidates\n"]},{"cell_type":"code","execution_count":11,"id":"bfdf5cda","metadata":{"execution":{"iopub.execute_input":"2025-08-09T20:31:28.782228Z","iopub.status.busy":"2025-08-09T20:31:28.782013Z","iopub.status.idle":"2025-08-09T20:31:29.422904Z","shell.execute_reply":"2025-08-09T20:31:29.422151Z","shell.execute_reply.started":"2025-08-09T20:31:28.782213Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded 400 chunks and embeddings (400, 768)\n","Collection 'hajj_e5' now has 400 embeddings.\n"]}],"source":["\n","# Load chunks and embeddings\n","with open(JSON_PATH, 'r', encoding='utf-8') as f:\n","    chunks = json.load(f)\n","embeddings = np.load(NPY_PATH)\n","\n","print(f\"Loaded {len(chunks)} chunks and embeddings {embeddings.shape}\")\n","\n","# Initialise Chroma client\n","client = chromadb.PersistentClient(path=CHROMA_PATH)\n","\n","# Drop existing collection if needed\n","try:\n","    client.delete_collection(name=COLLECTION_NAME)\n","except Exception:\n","    pass\n","\n","collection = client.get_or_create_collection(\n","    name=COLLECTION_NAME,\n","    metadata={'hnsw:space': 'cosine'}\n",")\n","\n","# Prepare ids, documents, metadatas\n","ids = [f\"chunk_{c['chunk_id']}\" for c in chunks]\n","texts = [c['text'] for c in chunks]\n","metadatas = [{'start_token': c['start_token'], 'end_token': c['end_token']} for c in chunks]\n","\n","# Add to collection in one call (small dataset)\n","collection.add(\n","    ids=ids,\n","    documents=texts,\n","    metadatas=metadatas,\n","    embeddings=embeddings.tolist()\n",")\n","\n","print(f\"Collection '{COLLECTION_NAME}' now has {collection.count()} embeddings.\")\n"]},{"cell_type":"code","execution_count":21,"id":"b1321456","metadata":{"execution":{"iopub.execute_input":"2025-08-09T20:44:51.446459Z","iopub.status.busy":"2025-08-09T20:44:51.446185Z","iopub.status.idle":"2025-08-09T20:44:51.452916Z","shell.execute_reply":"2025-08-09T20:44:51.452162Z","shell.execute_reply.started":"2025-08-09T20:44:51.446438Z"},"trusted":true},"outputs":[],"source":["# Example query\n","def search(query_str, top_k=10, re_rank=True):\n","    \"\"\"\n","    Search for relevant passages using vector similarity and optionally re-rank them.\n","    Args:\n","        query_str (str): User query.\n","        top_k (int): Number of candidates to retrieve from vector search.\n","        re_rank (bool): Whether to apply re-ranking to the candidates.\n","    Returns:\n","        list[dict]: List of hit dictionaries containing id, distance, text, metadata, and scores.\n","    \"\"\"\n","    query_embed = embed_query(query_str)\n","    result = collection.query(query_embeddings=[query_embed.tolist()], n_results=top_k)\n","    ids = result['ids'][0]\n","    dists = result['distances'][0]\n","    docs = result['documents'][0]\n","    metas = result['metadatas'][0]\n","    hits = []\n","    for i, (id_, dist) in enumerate(zip(ids, dists)):\n","        hit = {\n","            'id': id_,\n","            'distance': float(dist),\n","            'text': docs[i],\n","            'metadata': metas[i]\n","        }\n","        hits.append(hit)\n","    # Lexical overlap score\n","    query_tokens = set(query_str.lower().split())\n","    for h in hits:\n","        text_tokens = set(h['text'].lower().split())\n","        h['lexical_score'] = len(query_tokens & text_tokens)\n","    # Apply re-ranking if enabled\n","    if re_rank:\n","        # First, use cross-encoder for fine-grained scoring\n","        hits = rerank_cross_encoder(query_str, hits)\n","        # If cross-encoder is not available, sort by lexical score as fallback\n","        if not USE_CROSS_ENCODER:\n","            hits.sort(key=lambda x: x['lexical_score'], reverse=True)\n","    return hits\n"]},{"cell_type":"code","execution_count":32,"id":"f28fe47b-ed75-4be8-85ee-2ad747b71c2c","metadata":{"execution":{"iopub.execute_input":"2025-08-09T20:52:08.213724Z","iopub.status.busy":"2025-08-09T20:52:08.213111Z","iopub.status.idle":"2025-08-09T20:52:08.271938Z","shell.execute_reply":"2025-08-09T20:52:08.271289Z","shell.execute_reply.started":"2025-08-09T20:52:08.213699Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Top results for query: 'buy food'\n","\n","Rank 1: \n","distance=0.1793, \n","lexical_score=2, \n","text snippet=when going out during the day, avoid direct exposure to the sun and use a light coloured parasol - try to get enough sleep at night and avoid staying up late, because lack of sleep exposes the body to stress and lowers resistance protect yourself from food poisoning prevention guidelines : - avoid storing cooked food or eating it a long time after buying it, especially while moving for long periods - be careful when storing cooked food at room temperature for more than two hours as this leads to the proliferation of germs and the possibility of food poisoning - make sure to wash fruits and vegetables thoroughly before eating them - do not buy food from street vendors -\n","\n","\n","\n","Rank 2: \n","distance=0.2429, \n","lexical_score=2, \n","text snippet=eat regularly and drink plenty of fluids to prevent dehydration - do not buy food from street vendors face mask usage usage requirements : - prevent spread of infectious viruses - required when having cold symptoms - must cover nose, mouth, and chin - required at all times in grand mosque, prophet's mosque, during tawaf, sa'i and jamarat pelting - replace periodically or when dirty - dispose in dustbins coronavirus prevention transmission methods : - breathing - small droplets from nose or mouth falling on surfaces - touching contaminated surfaces then touching eyes, nose, or mouth preventive measures : - wash hands frequently with soap\n","\n","\n","\n","Rank 3: \n","distance=0.2473, \n","lexical_score=1, \n","text snippet=1. avoid storing cooked food or eating it long after distribution, especially after traveling between sites 2. properly wash fruits and vegetables before eating 3. avoid buying food from street vendors colds and respiratory diseases respiratory diseases are among the most common hajj diseases, caused by transmission of germs or viruses through coughing or sneezing. prevention : - avoid contact with infected people - do not use utensils used by others - wash hands regularly - avoid big crowds - avoid drinking very cold drinks - avoid direct air flows from air conditioners - always wear face masks to protect others treatment : - rest as much as possible - take pain\n","\n","\n","\n","Rank 4: \n","distance=0.2488, \n","lexical_score=2, \n","text snippet=proliferation of germs and the possibility of food poisoning - make sure to wash fruits and vegetables thoroughly before eating them - do not buy food from street vendors - make sure to eat an appropriate amount of food and drink plenty of fluids such as water and juices services provided at arafah your group usually sets up a camp for its members which includes a resting place and private toilets for the group. make sure to wear the bracelet of your group to benefit from the services provided at the camps. moving from arafah to muzdalifah guidelines for group travel : - be sure to adhere to the instructions given by the muta\n","\n","\n","\n","Rank 5: \n","distance=0.2098, \n","lexical_score=2, \n","text snippet=: - inform companions or group doctor about medical conditions and medications - carry prescriptions and medical case reports or cards - pharmacies available near grand mosque but not in mina, muzdalifah, and arafah - clinics and emergency centers available throughout holy sites food safety and poisoning prevention food safety guidelines : - avoid storing or eating food cooked and distributed long ago - do not keep cooked food at room temperature for more than two hours - wash fruits and vegetables before eating - eat regularly and drink plenty of fluids to prevent dehydration - do not buy food from street vendors face mask usage usage requirements : - prevent spread of infectious\n","\n","\n"]}],"source":["# Perform a search\n","query = \"buy food\"\n","hits = search(query, top_k=40, re_rank=True)\n","print(f\"Top results for query: '{query}'\")\n","for i, h in enumerate(hits[:5], 1):\n","    snippet = h['text'][:].replace(\"\\n\", \" \")\n","    print(f\"\\nRank {i}: \\ndistance={h['distance']:.4f}, \\nlexical_score={h['lexical_score']}, \\ntext snippet={snippet}\\n\\n\")\n"]},{"cell_type":"code","execution_count":null,"id":"0c929e01-256f-40a5-bbba-048b0b744143","metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":8040257,"sourceId":12720764,"sourceType":"datasetVersion"}],"dockerImageVersionId":31090,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"}},"nbformat":4,"nbformat_minor":5}
