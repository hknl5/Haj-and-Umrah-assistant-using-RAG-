{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12720764,"sourceType":"datasetVersion","datasetId":8040257}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"45956141","cell_type":"code","source":"import os\nos.environ['PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION'] = 'python'\n# Uncomment if chromadb is not installed\n!pip install --quiet chromadb transformers torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T19:08:13.281397Z","iopub.execute_input":"2025-08-09T19:08:13.282240Z","iopub.status.idle":"2025-08-09T19:09:51.823614Z","shell.execute_reply.started":"2025-08-09T19:08:13.282206Z","shell.execute_reply":"2025-08-09T19:09:51.822742Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.6/19.6 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.1/321.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 6.31.1 which is incompatible.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 6.31.1 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.31.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.31.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"id":"ce2d7dc9","cell_type":"code","source":"\nimport os\nimport json\nimport numpy as np\nimport torch\nfrom transformers import AutoTokenizer, AutoModel\nimport chromadb\n\n# Config\nMODEL_NAME = 'intfloat/e5-base-v2'\nCHROMA_PATH = 'hajj_e5_chroma'\nCOLLECTION_NAME = 'hajj_e5'\n\n# Prefixes\nPASSAGE_PREFIX = 'passage: '\nQUERY_PREFIX = 'query: '\n\n# Paths to load data\nJSON_PATH = '/kaggle/input/rijvxetjkr3wkr/hajj_chunks_e5.json'\nNPY_PATH = '/kaggle/input/rijvxetjkr3wkr/hajj_embeddings_e5.npy'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T19:13:42.262912Z","iopub.execute_input":"2025-08-09T19:13:42.263608Z","iopub.status.idle":"2025-08-09T19:13:49.473539Z","shell.execute_reply.started":"2025-08-09T19:13:42.263579Z","shell.execute_reply":"2025-08-09T19:13:49.472741Z"}},"outputs":[],"execution_count":2},{"id":"4b148223","cell_type":"code","source":"\n# Load model and tokenizer for query encoding\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel = AutoModel.from_pretrained(MODEL_NAME)\nmodel.to(device)\nmodel.eval()\n\n# Helper to encode and normalise text\ndef embed_query(text: str):\n    input_text = QUERY_PREFIX + text\n    encoded = tokenizer(input_text, return_tensors='pt', truncation=True, max_length=512)\n    encoded = {k: v.to(device) for k, v in encoded.items()}\n    with torch.no_grad():\n        out = model(**encoded)\n        token_embeds = out.last_hidden_state\n        mask = encoded['attention_mask'].unsqueeze(-1)\n        sum_embeds = (token_embeds * mask).sum(dim=1)\n        sum_mask = mask.sum(dim=1)\n        embed = (sum_embeds / sum_mask).squeeze(0).cpu().numpy()\n    # Normalise\n    norm = np.linalg.norm(embed)\n    if norm > 0:\n        embed = embed / norm\n    return embed\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T19:14:19.249645Z","iopub.execute_input":"2025-08-09T19:14:19.250331Z","iopub.status.idle":"2025-08-09T19:14:20.227364Z","shell.execute_reply.started":"2025-08-09T19:14:19.250309Z","shell.execute_reply":"2025-08-09T19:14:20.226557Z"}},"outputs":[],"execution_count":4},{"id":"bfdf5cda","cell_type":"code","source":"\n# Load chunks and embeddings\nwith open(JSON_PATH, 'r', encoding='utf-8') as f:\n    chunks = json.load(f)\nembeddings = np.load(NPY_PATH)\n\nprint(f\"Loaded {len(chunks)} chunks and embeddings {embeddings.shape}\")\n\n# Initialise Chroma client\nclient = chromadb.PersistentClient(path=CHROMA_PATH)\n\n# Drop existing collection if needed\ntry:\n    client.delete_collection(name=COLLECTION_NAME)\nexcept Exception:\n    pass\n\ncollection = client.get_or_create_collection(\n    name=COLLECTION_NAME,\n    metadata={'hnsw:space': 'cosine'}\n)\n\n# Prepare ids, documents, metadatas\nids = [f\"chunk_{c['chunk_id']}\" for c in chunks]\ntexts = [c['text'] for c in chunks]\nmetadatas = [{'start_token': c['start_token'], 'end_token': c['end_token']} for c in chunks]\n\n# Add to collection in one call (small dataset)\ncollection.add(\n    ids=ids,\n    documents=texts,\n    metadatas=metadatas,\n    embeddings=embeddings.tolist()\n)\n\nprint(f\"Collection '{COLLECTION_NAME}' now has {collection.count()} embeddings.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T19:14:42.478326Z","iopub.execute_input":"2025-08-09T19:14:42.478890Z","iopub.status.idle":"2025-08-09T19:14:43.326631Z","shell.execute_reply.started":"2025-08-09T19:14:42.478847Z","shell.execute_reply":"2025-08-09T19:14:43.325733Z"}},"outputs":[{"name":"stdout","text":"Loaded 400 chunks and embeddings (400, 768)\nCollection 'hajj_e5' now has 400 embeddings.\n","output_type":"stream"}],"execution_count":5},{"id":"b1321456","cell_type":"code","source":"\n# Example query\ndef search(query_str, top_k=10, re_rank=True):\n    query_embed = embed_query(query_str)\n    result = collection.query(query_embeddings=[query_embed.tolist()], n_results=top_k)\n    ids = result['ids'][0]\n    dists = result['distances'][0]\n    docs = result['documents'][0]\n    metas = result['metadatas'][0]\n    hits = []\n    for i, id_, dist in zip(range(len(ids)), ids, dists):\n        hits.append({'id': id_, 'distance': dist, 'text': docs[i], 'metadata': metas[i]})\n    # Lexical re‑ranking based on word overlap\n    if re_rank:\n        query_tokens = set(query_str.lower().split())\n        for h in hits:\n            text_tokens = set(h['text'].lower().split())\n            overlap = len(query_tokens & text_tokens)\n            h['lexical_score'] = overlap\n        hits.sort(key=lambda x: x['lexical_score'], reverse=True)\n    return hits\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T19:16:41.971409Z","iopub.execute_input":"2025-08-09T19:16:41.972011Z","iopub.status.idle":"2025-08-09T19:16:41.977752Z","shell.execute_reply.started":"2025-08-09T19:16:41.971988Z","shell.execute_reply":"2025-08-09T19:16:41.976925Z"}},"outputs":[],"execution_count":9},{"id":"71d997ed-6fee-4a91-a367-22fa07b8be7c","cell_type":"code","source":"# Perform a search\nquery = \"Tawaf steps\"\nhits = search(query, top_k=20, re_rank=True)\nprint(f\"Top results for query: '{query}'\")\nfor i, h in enumerate(hits[:5], 1):\n#    print(f\"Rank {i}: distance={h['distance']:.4f}, lexical_score={h['lexical_score']}, text snippet={h['text'][:150].replace('',' ')}\")\n    snippet = h['text'][:].replace(\"\\n\", \" \")\n    print(f\"\\nRank {i}: \\ndistance={h['distance']:.4f}, \\nlexical_score={h['lexical_score']}, \\ntext snippet={snippet}\\n\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T19:20:29.247807Z","iopub.execute_input":"2025-08-09T19:20:29.248465Z","iopub.status.idle":"2025-08-09T19:20:29.268751Z","shell.execute_reply.started":"2025-08-09T19:20:29.248443Z","shell.execute_reply":"2025-08-09T19:20:29.268026Z"}},"outputs":[{"name":"stdout","text":"Top results for query: 'Tawaf steps'\n\nRank 1: \ndistance=0.1527, \nlexical_score=2, \ntext snippet=##cautionary measures - special wheelchairs available for elderly and those in need sunnahs of tawaf : - al - ithtiba : men expose right shoulder during tawaf - ar - ramal : fast walking with small steps during first three circuits if possible - supplication : increase supplications, especially say between yemeni corner and black stone : \" rabbanaa aatinaa fid - dunyaa hassanatan wa fil aakhirati hassanah, waqinaa'adhaab - an - naar \" two rak'aas after tawaf\n\n\n\nRank 2: \ndistance=0.1275, \nlexical_score=1, \ntext snippet=- don't push in crowds - avoid placing feet on side brushes tawaf detailed instructions starting and ending tawaf : - begin from the black stone corner ( green sign indicates this on upper floors ) - perform takbeer ( allaahu akbar ) when passing the black stone each round - point toward black stone with hand, then begin tawaf with ka'ba to your left ( counterclockwise ) - kissing the black stone is sunnah if able, but difficult during crowded times - continue supplicating allah throughout tawaf - touch the yemeni corner if possible when reached - end each circuit at black\n\n\n\nRank 3: \ndistance=0.1505, \nlexical_score=1, \ntext snippet=performing tawaf. recite surah al - kaafiroon in first rak'aa and surah al - ikhlaas in second. drink zamzam water after tawaf as the prophet did. sa'i detailed instructions reaching sa'i area : after tawaf, follow panels guiding to sa'i area pointing towards safa. recommended to use upper floors to avoid ground floor crowding. use designated escalator entrances. about safa and marwa : safa and marwa are two small mountains where hagar climbed searching for food and water. safa is where sa'i\n\n\n\nRank 4: \ndistance=0.1505, \nlexical_score=1, \ntext snippet=but difficult during crowded times - continue supplicating allah throughout tawaf - touch the yemeni corner if possible when reached - end each circuit at black stone corner where you started - point and perform takbeer to complete one circuit - repeat until completing 7 circuits general tawaf tips : - don't stop inside tawaf area to avoid crowding - don't go opposite direction of tawaf - avoid crowded areas - wear face mask and follow precautionary measures - special wheelchairs available for elderly and those in need sunnahs of tawaf : - al - ithtiba : men expose\n\n\n\nRank 5: \ndistance=0.1521, \nlexical_score=1, \ntext snippet=official for exact umrah timing - know your residence location and save the address - remember your bus stop and meeting point - check gate panels for entry / exit suitability escalator safety - do not sit on escalators - stand firmly and hold the moving belt - women should ensure hijabs and jilbabs don't get stuck - walk immediately after reaching the end - don't take wheelchairs on escalators without help - assist elderly or inexperienced users - don't push in crowds - avoid placing feet on side brushes tawaf detailed instructions starting and ending tawaf : - begin from the black stone\n\n\n","output_type":"stream"}],"execution_count":13},{"id":"0a2938cb-7c44-47ba-8b6b-b6f28bfbd204","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}